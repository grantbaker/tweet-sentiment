{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import svm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrantMattModel():\n",
    "    def __init__(self):\n",
    "        with open('docModel.pkl','rb') as f:\n",
    "            self.embedding = pickle.load(f)\n",
    "    \n",
    "    def train(self, features, embeds, labels):\n",
    "        cores = 1\n",
    "        self.vectorizer = DictVectorizer(sparse=False)\n",
    "        self.sentiment = BaggingClassifier(svm.LinearSVC(), max_samples=1.0/cores,\n",
    "                                           n_estimators=cores, n_jobs=cores)\n",
    "        \n",
    "        feat_vec = self.vectorizer.fit_transform(features)\n",
    "        \n",
    "        embeds = np.concatenate((embeds, feat_vec), axis=1)\n",
    "        self.sentiment.fit(embeds, labels)\n",
    "        \n",
    "    def extract_features(self, tweet):\n",
    "        feats = {}\n",
    "        tweet = tweet.split(' ')\n",
    "        feats['NUMCAPS'] = 0\n",
    "        feats['LENGTH'] = len(tweet)\n",
    "        for j in range(len(tweet)):\n",
    "            word = tweet[j]\n",
    "\n",
    "            if len(word) > 0 and word[0] != '@':\n",
    "#                 feats['WORD='+word.lower()] = 1\n",
    "                feats['NUMCAPS'] += sum(1 for char in word if char.isupper())\n",
    "        return feats\n",
    "    \n",
    "    def embed_tweet(self,tweet):\n",
    "        tweet = tweet.split(' ')\n",
    "        out = np.zeros(100)\n",
    "        for j in range(len(tweet)):\n",
    "            word = tweet[j]\n",
    "            if len(word) > 0 and word[0] != '@':\n",
    "                if word in self.embedding.wv.vocab:\n",
    "                    out += self.embedding[word]\n",
    "        return out/len(tweet)\n",
    "\n",
    "    def predict(self, newTweet):\n",
    "        feats = self.extract_features(newTweet)\n",
    "        feat_vec = self.vectorizer.transform(feats)\n",
    "        embed = self.embed_tweet(newTweet)\n",
    "        \n",
    "        feat_vec = feat_vec[0]\n",
    "        tweet_vec = np.concatenate((embed, feat_vec)).reshape((1,-1))\n",
    "        \n",
    "        return self.sentiment.decision_function(tweet_vec)[0]\n",
    "    \n",
    "    def evaluate(self, test_df):\n",
    "        test_labels = test_df.as_matrix(columns=['sentiment']).flatten()/2-1\n",
    "        test_features = [self.extract_features(test_df['text'][i]) for i in range(len(test_df))]\n",
    "        test_embeds = np.zeros((len(test_df), 100))\n",
    "        for i in range(len(test_df)):\n",
    "            test_embeds[i] = self.embed_tweet(test_df['text'][i])\n",
    "        feat_vec = self.vectorizer.transform(test_features)\n",
    "        test_vec = np.concatenate((test_embeds, feat_vec), axis=1)\n",
    "        \n",
    "        acc = self.sentiment.score(test_vec, test_labels)\n",
    "#         pred_labels = np.tanh(self.sentiment.decision_function(feat_vec))\n",
    "#         conf_acc = (test_labels + pred_labels)/(2*len(test_df))\n",
    "#         return (acc, conf_acc)\n",
    "        return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sentiment','id','date','query_string','user','text']\n",
    "tweet_df = pd.read_csv('training.1600000.processed.noemoticon.csv',\n",
    "                              header=None, names=cols, encoding='utf-8')\n",
    "tweet_df.drop(['id','date','query_string','user'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = GrantMattModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "tweet_list = tweet_df['text'].tolist()\n",
    "p = Pool(8)\n",
    "features = p.map(gm.extract_features, tweet_list)\n",
    "embeds = p.map(gm.embed_tweet, tweet_list)\n",
    "embeds = np.array(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n"
     ]
    }
   ],
   "source": [
    "features = [{} for _ in range(len(tweet_df))]\n",
    "embeds = np.zeros((len(tweet_df), 100))\n",
    "for i in range(len(tweet_df)):\n",
    "    features[i] = gm.extract_features(tweet_df['text'][i])\n",
    "    embeds[i] = gm.embed_tweet(tweet_df['text'][i])\n",
    "    \n",
    "    if i % 100000 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tweet_df.as_matrix(columns=['sentiment']).flatten()/2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.train(features, embeds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df =  pd.read_csv('testdata.manual.2009.06.14.csv',\n",
    "                       header=None, names=cols, encoding='utf-8')\n",
    "test_df.drop(['id','date','query_string','user'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49\n",
      "0.00015676438808441163\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "n = 400\n",
    "start = time()\n",
    "print(gm.evaluate(test_df[:n]))\n",
    "print((time()-start)/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('modelv03.pickle','wb') as f:\n",
    "    pickle.dump(gm, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-11f3204c7457>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnewTweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"At least I'm not dead yet!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewTweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sentiment:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gm' is not defined"
     ]
    }
   ],
   "source": [
    "newTweet = \"At least I'm not dead yet!\"\n",
    "\n",
    "score = gm.predict(newTweet)\n",
    "print('Sentiment:', score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hey grant, can you turn classification into a pipeline? \n",
    "# I think I can import a pickle'd pipeline into java. -- Sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = gm.vectorizer\n",
    "s = gm.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.vectorizer = v\n",
    "gm.sentiment = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('modelv02.pickle','rb') as f:\n",
    "    gm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del gm.embedding\n",
    "del gm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
